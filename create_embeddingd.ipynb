{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b88767fc",
   "metadata": {},
   "source": [
    "**Load the PDF content**\n",
    "\n",
    "This script is to initialize the pdf path and use it later for loading the documents in chunks. This may take time. Please run it step by step to create the vector db in folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb90ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_docling import DoclingLoader\n",
    "\n",
    "FILE_PATH = \"https://arxiv.org/pdf/2408.09869\"\n",
    "\n",
    "loader = DoclingLoader(file_path=FILE_PATH)\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1a42b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in docs[:3]:\n",
    "    print(f\"- {d.page_content=}\")\n",
    "    print(f\"- {d.metadata=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae5586d",
   "metadata": {},
   "source": [
    "This step is to extract only the valuable info for metadata for each docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97649445",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "def flatten_docling_metadata(docs):\n",
    "    flattened_docs = []\n",
    "    for doc in docs:\n",
    "        # Extract critical fields from dl_meta\n",
    "        dl_meta = doc.metadata.get(\"dl_meta\", {})\n",
    "        headings = \", \".join(dl_meta.get(\"headings\", []))\n",
    "        filename = dl_meta.get(\"origin\", {}).get(\"filename\", \"unknown\")\n",
    "        page_nos = {item[\"prov\"][0][\"page_no\"] for item in dl_meta.get(\"doc_items\", [])}\n",
    "        \n",
    "        # Build simplified metadata\n",
    "        simple_metadata = {\n",
    "            \"source\": doc.metadata[\"source\"],  # Keep original source\n",
    "            \"filename\": filename,\n",
    "            \"headings\": headings,\n",
    "            \"page_nos\": \", \".join(map(str, sorted(page_nos))),\n",
    "        }\n",
    "        \n",
    "        flattened_docs.append(Document(\n",
    "            page_content=doc.page_content,\n",
    "            metadata=simple_metadata\n",
    "        ))\n",
    "    return flattened_docs\n",
    "\n",
    "# Process your documents\n",
    "flattened_docs = flatten_docling_metadata(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e7eb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in flattened_docs[:3]:\n",
    "    print(f\"- {d.page_content=}\")\n",
    "    print(f\"- {d.metadata=}\")\n",
    "\n",
    "# You can see the difference in metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de281ef3",
   "metadata": {},
   "source": [
    "**Step to create embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d749bca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Initialize embedding model (e.g., HuggingFace)\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    ")\n",
    "\n",
    "# Create ChromaDB vector store\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=flattened_docs,           # Your loaded/chunked documents\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=\"./chroma_db\"  # Save to disk to use it later\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5f8280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can query it!\n",
    "results = vector_db.similarity_search(\"What is docling?\", k=3)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
